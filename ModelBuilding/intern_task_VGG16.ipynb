{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1iMJF2DtyFfjnVbZdHQ7SXjyIhrAgL6MD","authorship_tag":"ABX9TyOJOU2DNTq5pUlllt5sgbmi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"GGnxZ1RzVMHj","executionInfo":{"status":"ok","timestamp":1739083711246,"user_tz":-330,"elapsed":7309,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.metrics import accuracy_score , classification_report , multilabel_confusion_matrix\n","import cv2\n","import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential , Model\n","from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,GlobalAveragePooling2D\n","from tensorflow.keras.activations import relu,softmax\n","\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","import sys\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.utils import to_categorical\n","import json"]},{"cell_type":"code","source":["class VGG16Model :\n","  def __init__(self, train_path , validation_path , model_path) :\n","    try :\n","      self.train_path = train_path\n","      self.validation_path = validation_path\n","      self.target_labels = os.listdir(self.train_path)\n","      self.model_path = model_path\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def ImageProcessing(self) :\n","    try :\n","      train_data_process = ImageDataGenerator(rescale=1/255 ,\n","                                  shear_range = 0.2 ,\n","                                  zoom_range = 0.2 ,\n","                                  horizontal_flip = True)\n","      val_data_process = ImageDataGenerator(rescale=1/255)\n","\n","      self.train_data = train_data_process.flow_from_directory(self.train_path ,\n","                                                      target_size = (256,256),\n","                                                      classes = self.target_labels ,\n","                                                      class_mode = \"categorical\",\n","                                                      batch_size = 16)\n","\n","      self.validation_data = val_data_process.flow_from_directory(self.validation_path ,\n","                                                                  classes = self.target_labels,\n","                                                                  target_size=(256,256),\n","                                                                  class_mode = \"categorical\")\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Model(self) :\n","    try:\n","      v16 = VGG16(input_shape=[256,256]+[3] , weights=\"imagenet\" , include_top=False)\n","      for layer in v16.layers :\n","        layer.trainable = False\n","      x = GlobalAveragePooling2D()(v16.output)\n","      predict = Dense(len(self.target_labels),activation='softmax')(x)\n","      self.model = Model(inputs = v16.inputs,outputs=predict)\n","      self.model.compile(optimizer=\"adam\" , loss = \"categorical_crossentropy\" , metrics = [\"Accuracy\"])\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Training(self) :\n","    try :\n","      self.Model()\n","      self.ImageProcessing()\n","      self.model.fit(self.train_data,\n","                    validation_data = self.validation_data,\n","                    epochs=5)\n","\n","      self.model.save(f'{self.model_path}/VGG16_model.h5')\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n"],"metadata":{"id":"0ObmPh4DltJe","executionInfo":{"status":"ok","timestamp":1739083711262,"user_tz":-330,"elapsed":6,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\" :\n","  train_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Train_data\"\n","  validation_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Validation_data\"\n","  model_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model\"\n","\n","  v16_Model = VGG16Model(train_path , validation_path , model_path)\n","  v16_Model.Training()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2kDKvDYMUyN","executionInfo":{"status":"ok","timestamp":1739087995269,"user_tz":-330,"elapsed":4284009,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"3f0c7595-027e-466b-df3c-6e428ebaecc2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","Found 5094 images belonging to 34 classes.\n","Found 1020 images belonging to 34 classes.\n","Epoch 1/5\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3568s\u001b[0m 11s/step - Accuracy: 0.0875 - loss: 3.4234 - val_Accuracy: 0.2686 - val_loss: 2.9515\n","Epoch 2/5\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 499ms/step - Accuracy: 0.3084 - loss: 2.8899 - val_Accuracy: 0.3951 - val_loss: 2.5844\n","Epoch 3/5\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 501ms/step - Accuracy: 0.4120 - loss: 2.5633 - val_Accuracy: 0.4627 - val_loss: 2.3375\n","Epoch 4/5\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 480ms/step - Accuracy: 0.4449 - loss: 2.3593 - val_Accuracy: 0.4627 - val_loss: 2.1699\n","Epoch 5/5\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 475ms/step - Accuracy: 0.4598 - loss: 2.2134 - val_Accuracy: 0.5020 - val_loss: 2.0379\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["class Evaluation :\n","  def __init__(self , test_path , model) :\n","    try :\n","      self.model = model\n","      self.test_path = test_path\n","      self.target_labels = sorted(os.listdir(self.test_path))\n","      test_data_process = ImageDataGenerator(rescale=1/255)\n","      self.test_data = test_data_process.flow_from_directory(self.test_path,\n","                                                          classes = self.target_labels,\n","                                                          target_size=(256,256),\n","                                                          class_mode = \"categorical\")\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","  def Validation(self , report_path) :\n","    try:\n","      y_true = np.array(self.test_data.labels)\n","      y_true = to_categorical(y_true, num_classes=len(self.target_labels))\n","      y_pred_prob = self.model.predict(self.test_data)  # Get probability scores\n","      y_pred = (y_pred_prob > 0.5).astype(int)\n","      conf_matrices = multilabel_confusion_matrix(y_true, y_pred)\n","\n","      # Summing over all labels to get overall TP, TN, FP, FN\n","      TP = conf_matrices[:, 1, 1].sum()\n","      TN = conf_matrices[:, 0, 0].sum()\n","      FP = conf_matrices[:, 0, 1].sum()\n","      FN = conf_matrices[:, 1, 0].sum()\n","\n","      accuracy = (TP + TN) / (TP + TN + FP + FN)\n","      precision = TP/(TP+FP) if (TP + FP) > 0 else 0\n","      recall = TP / (TP+FN) if (TP + FN) > 0 else 0\n","      f1_sc = 2 * ((precision*recall) / (precision + recall)) if (precision + recall) > 0 else 0\n","\n","      report = {\"True Positives\" : TP,\n","                \"True Negatives\" : TN,\n","                \"Flase Positives\" : FP,\n","                \"False Negatives\" : FN ,\n","                \"Accuracy\" : accuracy ,\n","                \"Precision\" : precision ,\n","                \"Recall\" : recall,\n","                \"F1_Score\" : f1_sc\n","                }\n","\n","      def convert_numpy(obj):\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()  # Convert arrays to lists\n","        elif isinstance(obj, (np.int64, np.int32)):\n","            return int(obj)  # Convert NumPy integers to Python int\n","        elif isinstance(obj, (np.float64, np.float32)):\n","            return float(obj)  # Convert NumPy floats to Python float\n","        else:\n","            return obj\n","\n","      with open(report_path, \"w\") as json_file:\n","        json.dump(report, json_file, indent=4 , default=convert_numpy)\n","\n","\n","      print(f\"Classification report saved successfully\")\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n"],"metadata":{"id":"-0HlGp3tak0Y","executionInfo":{"status":"ok","timestamp":1739087995315,"user_tz":-330,"elapsed":40,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/VGG16_model.h5\")\n","test_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Test_data\"\n","obj = Evaluation(test_path , model)\n","obj.Validation(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/VGG16_validation_report.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALGYVLTPc_oC","executionInfo":{"status":"ok","timestamp":1739088416511,"user_tz":-330,"elapsed":421197,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"14a65c2b-fc31-456c-f96b-0b380f47722d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Found 680 images belonging to 34 classes.\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 16s/step\n","Classification report saved successfully\n"]}]}]}