{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yOtztd0b_Mdut-nnanmLvYZZeik9J_qE","authorship_tag":"ABX9TyPh1yX7UR3iggKV8CWhO7CW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jTD-DkXL1mXM","executionInfo":{"status":"ok","timestamp":1738925908697,"user_tz":-330,"elapsed":34,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"GGnxZ1RzVMHj","executionInfo":{"status":"ok","timestamp":1738925920921,"user_tz":-330,"elapsed":12188,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.metrics import accuracy_score , classification_report , multilabel_confusion_matrix\n","import cv2\n","import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential , Model\n","from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten , GlobalAveragePooling2D\n","from tensorflow.keras.activations import relu,softmax\n","\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","import sys\n","\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.utils import to_categorical\n","import json"]},{"cell_type":"code","source":["class ResNetModel :\n","  def __init__(self, train_path , validation_path , model_path) :\n","    try :\n","      self.train_path = train_path\n","      self.validation_path = validation_path\n","      self.target_labels = os.listdir(self.train_path)\n","      self.model_path = model_path\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def ImageProcessing(self) :\n","    try :\n","      train_data_process = ImageDataGenerator(rescale=1/255 ,\n","                                  shear_range = 0.2 ,\n","                                  zoom_range = 0.2 ,\n","                                  horizontal_flip = True)\n","      val_data_process = ImageDataGenerator(rescale=1/255)\n","\n","      self.train_data = train_data_process.flow_from_directory(self.train_path ,\n","                                                      target_size = (256,256),\n","                                                      classes = self.target_labels ,\n","                                                      class_mode = \"categorical\",\n","                                                      batch_size = 16)\n","\n","      self.validation_data = val_data_process.flow_from_directory(self.validation_path ,\n","                                                                  classes = self.target_labels,\n","                                                                  target_size=(256,256),\n","                                                                  class_mode = \"categorical\")\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Model(self) :\n","    try:\n","      r50 = ResNet50(input_shape=(256, 256, 3) , weights=\"imagenet\" , include_top=False)\n","      for layer in r50.layers :\n","        layer.trainable = False\n","      x = GlobalAveragePooling2D()(r50.output)\n","      predict = Dense(len(self.target_labels),activation='softmax')(x)\n","      self.model = Model(inputs = r50.inputs,outputs=predict)\n","      self.model.compile(optimizer=\"adam\" , loss = \"categorical_crossentropy\" , metrics = [\"Accuracy\"])\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Training(self) :\n","    try :\n","      self.Model()\n","      self.ImageProcessing()\n","      self.model.fit(self.train_data,\n","                    validation_data = self.validation_data,\n","                    epochs=10)\n","\n","      self.model.save(f'{self.model_path}/ResNet_model.h5')\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n"],"metadata":{"id":"0ObmPh4DltJe","executionInfo":{"status":"ok","timestamp":1738943636927,"user_tz":-330,"elapsed":45,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\" :\n","  train_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Train_data\"\n","  validation_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Validation_data\"\n","  model_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model\"\n","\n","  RN_Model = ResNetModel(train_path , validation_path , model_path)\n","  RN_Model.Training()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2kDKvDYMUyN","executionInfo":{"status":"ok","timestamp":1738943421153,"user_tz":-330,"elapsed":5515268,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"aee79504-ef4d-4ef5-924c-397265022ef6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Found 5094 images belonging to 34 classes.\n","Found 1020 images belonging to 34 classes.\n","Epoch 1/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2244s\u001b[0m 7s/step - Accuracy: 0.0354 - loss: 3.6803 - val_Accuracy: 0.0686 - val_loss: 3.4228\n","Epoch 2/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1680s\u001b[0m 5s/step - Accuracy: 0.0638 - loss: 3.4670 - val_Accuracy: 0.0882 - val_loss: 3.3936\n","Epoch 3/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1678s\u001b[0m 5s/step - Accuracy: 0.0698 - loss: 3.4163 - val_Accuracy: 0.0922 - val_loss: 3.3243\n","Epoch 4/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1677s\u001b[0m 5s/step - Accuracy: 0.0866 - loss: 3.3432 - val_Accuracy: 0.0824 - val_loss: 3.3311\n","Epoch 5/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1694s\u001b[0m 5s/step - Accuracy: 0.0807 - loss: 3.3270 - val_Accuracy: 0.1078 - val_loss: 3.2684\n","Epoch 6/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1717s\u001b[0m 5s/step - Accuracy: 0.0993 - loss: 3.2952 - val_Accuracy: 0.0843 - val_loss: 3.2877\n","Epoch 7/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1665s\u001b[0m 5s/step - Accuracy: 0.1024 - loss: 3.2723 - val_Accuracy: 0.1216 - val_loss: 3.2609\n","Epoch 8/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1720s\u001b[0m 5s/step - Accuracy: 0.1055 - loss: 3.2529 - val_Accuracy: 0.1216 - val_loss: 3.2384\n","Epoch 9/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 5s/step - Accuracy: 0.1047 - loss: 3.2370 - val_Accuracy: 0.1039 - val_loss: 3.2006\n","Epoch 10/10\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1706s\u001b[0m 5s/step - Accuracy: 0.1193 - loss: 3.2219 - val_Accuracy: 0.1402 - val_loss: 3.1692\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["class Evaluation :\n","  def __init__(self , test_path , model) :\n","    try :\n","      self.model = model\n","      self.test_path = test_path\n","      self.target_labels = sorted(os.listdir(self.test_path))\n","      test_data_process = ImageDataGenerator(rescale=1/255)\n","      self.test_data = test_data_process.flow_from_directory(self.test_path,\n","                                                          classes = self.target_labels,\n","                                                          target_size=(256,256),\n","                                                          class_mode = \"categorical\")\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","  def Validation(self , report_path) :\n","    try:\n","      y_true = np.array(self.test_data.labels)\n","      y_true = to_categorical(y_true, num_classes=len(self.target_labels))\n","      y_pred_prob = self.model.predict(self.test_data)  # Get probability scores\n","      y_pred = (y_pred_prob > 0.5).astype(int)\n","      conf_matrices = multilabel_confusion_matrix(y_true, y_pred)\n","\n","      # Summing over all labels to get overall TP, TN, FP, FN\n","      TP = conf_matrices[:, 1, 1].sum()\n","      TN = conf_matrices[:, 0, 0].sum()\n","      FP = conf_matrices[:, 0, 1].sum()\n","      FN = conf_matrices[:, 1, 0].sum()\n","\n","      accuracy = (TP + TN) / (TP + TN + FP + FN)\n","      precision = TP/(TP+FP) if (TP + FP) > 0 else 0\n","      recall = TP / (TP+FN) if (TP + FN) > 0 else 0\n","      f1_sc = 2 * ((precision*recall) / (precision + recall)) if (precision + recall) > 0 else 0\n","\n","      report = {\"True Positives\" : TP,\n","                \"True Negatives\" : TN,\n","                \"Flase Positives\" : FP,\n","                \"False Negatives\" : FN ,\n","                \"Accuracy\" : accuracy ,\n","                \"Precision\" : precision ,\n","                \"Recall\" : recall,\n","                \"F1_Score\" : f1_sc\n","                }\n","\n","      def convert_numpy(obj):\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()  # Convert arrays to lists\n","        elif isinstance(obj, (np.int64, np.int32)):\n","            return int(obj)  # Convert NumPy integers to Python int\n","        elif isinstance(obj, (np.float64, np.float32)):\n","            return float(obj)  # Convert NumPy floats to Python float\n","        else:\n","            return obj\n","\n","      with open(report_path, \"w\") as json_file:\n","        json.dump(report, json_file, indent=4 , default=convert_numpy)\n","\n","\n","      print(f\"Classification report saved successfully\")\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n"],"metadata":{"id":"-0HlGp3tak0Y","executionInfo":{"status":"ok","timestamp":1738943662426,"user_tz":-330,"elapsed":9,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/ResNet_model.h5\")\n","test_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Test_data\"\n","obj = Evaluation(test_path , model)\n","obj.Validation(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/ResNet_validation_report.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALGYVLTPc_oC","executionInfo":{"status":"ok","timestamp":1738943984619,"user_tz":-330,"elapsed":291659,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"47d450eb-6bc5-4a00-f55d-d9e584fe9af2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Found 680 images belonging to 34 classes.\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 10s/step\n","Classification report saved successfully\n"]}]}]}