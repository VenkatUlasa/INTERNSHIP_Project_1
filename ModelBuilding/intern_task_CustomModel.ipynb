{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1BQUsIDpsJD_Vt_SzFZo8ByfwsM6robAV","authorship_tag":"ABX9TyMVnPJX7dQpW+oIOHJ2qqvu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":44,"metadata":{"id":"GGnxZ1RzVMHj","executionInfo":{"status":"ok","timestamp":1738922073274,"user_tz":-330,"elapsed":15,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn.metrics import accuracy_score , classification_report , multilabel_confusion_matrix\n","import cv2\n","import tensorflow\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten\n","from tensorflow.keras.activations import relu,softmax\n","from tensorflow.keras.utils import to_categorical\n","\n","import os\n","import warnings\n","warnings.filterwarnings('ignore')\n","import sys\n","import json"]},{"cell_type":"code","source":["def splitting_data(dest_path , req_images) :\n","  try :\n","    import os\n","    import random\n","    import shutil\n","    # Define the source and destination directories\n","    source_directory = '/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/InternShip'  # Modify with the path to your source folder\n","    destination_directory = dest_path  # Modify with the path to your destination folder\n","    # Create the destination directory if it doesn't exist\n","    if not os.path.exists(destination_directory):\n","        os.makedirs(destination_directory)\n","    # Loop through each folder in the source directory\n","    for folder_name in os.listdir(source_directory):\n","        folder_path = os.path.join(source_directory, folder_name)\n","        # Check if it's a directory (not a file)\n","        if os.path.isdir(folder_path):\n","            # Create a new folder in the destination directory with the same name\n","            new_folder_path = os.path.join(destination_directory, folder_name)\n","            if not os.path.exists(new_folder_path):\n","                os.makedirs(new_folder_path)\n","            # Get all images in the current folder\n","            images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n","            # Select 200 random images (or fewer if there are less than 200)\n","            selected_images = random.sample(images, min(req_images, len(images)))\n","            # Copy the selected images to the new folder in the destination directory\n","            for image in selected_images:\n","                source_image = os.path.join(folder_path, image)\n","                destination_image = os.path.join(new_folder_path, image)\n","                shutil.copy(source_image, destination_image)\n","            print(f\"Processed folder '{folder_name}': {len(selected_images)} images copied.\")\n","  except Exception as e :\n","    er_type, er_msg, line_no = sys.exc_info()\n","    print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')"],"metadata":{"id":"tmT8QRtJcnqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# splitting_data(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Train_data\" , 150)"],"metadata":{"collapsed":true,"id":"EdNJIcGkerg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# splitting_data(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Test_data\" , 20)"],"metadata":{"collapsed":true,"id":"Y6m4rMrgf0ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# splitting_data(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Validation_data\" , 30)"],"metadata":{"collapsed":true,"id":"GDkLENp2f110"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomModel :\n","  def __init__(self, train_path , test_path , validation_path , model_path) :\n","    try :\n","      self.train_path = train_path\n","      self.test_path = test_path\n","      self.validation_path = validation_path\n","      self.target_labels = os.listdir(self.train_path)\n","      self.model = Sequential()\n","      self.model_path = model_path\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def ImageProcessing(self) :\n","    try :\n","      train_data_process = ImageDataGenerator(rescale=1/255 ,\n","                                  shear_range = 0.2 ,\n","                                  zoom_range = 0.2 ,\n","                                  horizontal_flip = True)\n","      test_data_process = ImageDataGenerator(rescale=1/255)\n","      val_data_process = ImageDataGenerator(rescale=1/255)\n","\n","      self.train_data = train_data_process.flow_from_directory(self.train_path ,\n","                                                      target_size = (256,256),\n","                                                      classes = self.target_labels ,\n","                                                      class_mode = \"categorical\",\n","                                                      batch_size = 16)\n","      self.test_data = test_data_process.flow_from_directory(self.test_path,\n","                                                          classes = self.target_labels,\n","                                                          target_size=(256,256))\n","\n","      self.validation_data = val_data_process.flow_from_directory(self.validation_path ,\n","                                                                  classes = self.target_labels,\n","                                                                  target_size=(256,256))\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Model(self) :\n","    try :\n","      self.model.add(Conv2D(128 , kernel_size = (3,3) , input_shape = (int(256),int(256),3) , padding='same',activation='relu'))\n","      self.model.add(MaxPool2D(pool_size = (2,2)))\n","      # second kernel and max poo layers\n","      self.model.add(Conv2D(64 , kernel_size = (3,3), padding='same',activation='relu'))\n","      self.model.add(MaxPool2D(pool_size = (2,2)))\n","      # third kernel and max poo layers\n","      self.model.add(Conv2D(32 , kernel_size = (3,3), padding='same',activation='relu'))\n","      self.model.add(MaxPool2D(pool_size = (2,2)))\n","      # forth kernel and max poo layers\n","      self.model.add(Conv2D(6 , kernel_size = (3,3), padding='same',activation='relu'))\n","      self.model.add(MaxPool2D(pool_size = (2,2)))\n","      self.model.add(Flatten()) # one dimensional array\n","      # above 1d data give to ANN\n","      self.model.add(Dense(32,activation='relu')) # hiddel layer 1\n","      self.model.add(Dense(16,activation = 'relu')) # hiddel layer 2\n","\n","      # output layer\n","      self.model.add(Dense(len(self.target_labels),activation='softmax'))\n","      self.model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['Accuracy'])\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","\n","  def Training(self) :\n","    try :\n","      self.Model()\n","      self.ImageProcessing()\n","      self.model.fit(self.train_data,\n","                    validation_data = self.validation_data,\n","                    epochs=15)\n","\n","      self.model.save(f'{self.model_path}/custom_model.h5')\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n"],"metadata":{"id":"0ObmPh4DltJe","executionInfo":{"status":"ok","timestamp":1738915859359,"user_tz":-330,"elapsed":12,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\" :\n","  train_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Train_data\"\n","  test_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Test_data\"\n","  validation_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Validation_data\"\n","  model_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model\"\n","\n","  c_Model = CustomModel(train_path , test_path , validation_path , model_path)\n","  c_Model.Training()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-ScHTRwqeAQ","executionInfo":{"status":"ok","timestamp":1738843896398,"user_tz":-330,"elapsed":32296739,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"5fa882ff-c0a8-415a-bd32-231f9daf5c49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5094 images belonging to 34 classes.\n","Found 680 images belonging to 34 classes.\n","Found 1020 images belonging to 34 classes.\n","Epoch 1/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2569s\u001b[0m 8s/step - Accuracy: 0.0301 - loss: 3.5268 - val_Accuracy: 0.0235 - val_loss: 3.5263\n","Epoch 2/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2124s\u001b[0m 7s/step - Accuracy: 0.0272 - loss: 3.5257 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 3/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2119s\u001b[0m 7s/step - Accuracy: 0.0288 - loss: 3.5267 - val_Accuracy: 0.0304 - val_loss: 3.5264\n","Epoch 4/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2136s\u001b[0m 7s/step - Accuracy: 0.0257 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 5/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2103s\u001b[0m 7s/step - Accuracy: 0.0240 - loss: 3.5270 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 6/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2106s\u001b[0m 7s/step - Accuracy: 0.0220 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 7/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2109s\u001b[0m 7s/step - Accuracy: 0.0272 - loss: 3.5268 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 8/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2115s\u001b[0m 7s/step - Accuracy: 0.0272 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 9/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2129s\u001b[0m 7s/step - Accuracy: 0.0296 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 10/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2150s\u001b[0m 7s/step - Accuracy: 0.0263 - loss: 3.5266 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 11/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2132s\u001b[0m 7s/step - Accuracy: 0.0218 - loss: 3.5268 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 12/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2155s\u001b[0m 7s/step - Accuracy: 0.0275 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 13/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2105s\u001b[0m 7s/step - Accuracy: 0.0281 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 14/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2099s\u001b[0m 7s/step - Accuracy: 0.0216 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n","Epoch 15/15\n","\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2121s\u001b[0m 7s/step - Accuracy: 0.0228 - loss: 3.5267 - val_Accuracy: 0.0294 - val_loss: 3.5264\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["class Evaluation :\n","  def __init__(self , test_path , model) :\n","    try :\n","      self.model = model\n","      self.test_path = test_path\n","      self.target_labels = sorted(os.listdir(self.test_path))\n","      test_data_process = ImageDataGenerator(rescale=1/255)\n","      self.test_data = test_data_process.flow_from_directory(self.test_path,\n","                                                          classes = self.target_labels,\n","                                                          target_size=(256,256))\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n","  def Validation(self , report_path) :\n","    try:\n","      y_true = np.array(self.test_data.labels)\n","      y_true = to_categorical(y_true, num_classes=len(self.target_labels))\n","      y_pred_prob = self.model.predict(self.test_data)  # Get probability scores\n","      y_pred = (y_pred_prob > 0.5).astype(int)\n","      conf_matrices = multilabel_confusion_matrix(y_true, y_pred)\n","\n","      # Summing over all labels to get overall TP, TN, FP, FN\n","      TP = conf_matrices[:, 1, 1].sum()\n","      TN = conf_matrices[:, 0, 0].sum()\n","      FP = conf_matrices[:, 0, 1].sum()\n","      FN = conf_matrices[:, 1, 0].sum()\n","\n","      accuracy = (TP + TN) / (TP + TN + FP + FN)\n","      precision = TP/(TP+FP) if (TP + FP) > 0 else 0\n","      recall = TP / (TP+FN) if (TP + FN) > 0 else 0\n","      f1_sc = 2 * ((precision*recall) / (precision + recall)) if (precision + recall) > 0 else 0\n","\n","      report = {\"True Positives\" : TP,\n","                \"True Negatives\" : TN,\n","                \"Flase Positives\" : FP,\n","                \"False Negatives\" : FN ,\n","                \"Accuracy\" : accuracy ,\n","                \"Precision\" : precision ,\n","                \"Recall\" : recall,\n","                \"F1_Score\" : f1_sc\n","                }\n","\n","      def convert_numpy(obj):\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()  # Convert arrays to lists\n","        elif isinstance(obj, (np.int64, np.int32)):\n","            return int(obj)  # Convert NumPy integers to Python int\n","        elif isinstance(obj, (np.float64, np.float32)):\n","            return float(obj)  # Convert NumPy floats to Python float\n","        else:\n","            return obj\n","\n","      with open(report_path, \"w\") as json_file:\n","        json.dump(report, json_file, indent=4 , default=convert_numpy)\n","\n","\n","      print(f\"Classification report saved successfully\")\n","\n","    except Exception as e :\n","      er_type, er_msg, line_no = sys.exc_info()\n","      print(f'{er_type} <-----> {er_msg} <-----> {line_no.tb_lineno}')\n",""],"metadata":{"id":"-0HlGp3tak0Y","executionInfo":{"status":"ok","timestamp":1738921205021,"user_tz":-330,"elapsed":25,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["model = tensorflow.keras.models.load_model(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/custom_model.h5\")\n","test_path = \"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Test_data\"\n","obj = Evaluation(test_path , model)\n","obj.Validation(\"/content/drive/MyDrive/INTERNSHIP FOLDER/task 1/Model/validation_report.json\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALGYVLTPc_oC","executionInfo":{"status":"ok","timestamp":1738921287057,"user_tz":-330,"elapsed":75548,"user":{"displayName":"Venkat Ulasa","userId":"11163600371612428690"}},"outputId":"6539b72d-cbe0-4452-a327-6fdaed5a9bc0"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Found 680 images belonging to 34 classes.\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step\n","Classification report saved successfully\n"]}]}]}